{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HRNet이 384x288이지만, 지금 영상이 고화질이다보니 대부분 사람 크기가 그 두배 좀 안됨.\n",
    "그러므로 사람을 그 두배인 768x576크기로 만들자.\n",
    "하지만 가급적이면 비율이 맞도록"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 라이브러리 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from io import TextIOWrapper\n",
    "from pathlib import Path\n",
    "from typing import Callable, List, Sequence, Tuple\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.model_selection import KFold\n",
    "from torch import nn, optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from tqdm import tqdm\n",
    "\n",
    "import utils\n",
    "import networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 하이퍼 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_DIR = Path(\"results/box학습\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-4  # transfer learning이니깐 좀 작게 주는게 좋을 것 같아서 1e-4\n",
    "BATCH_SIZE = 10\n",
    "START_EPOCH = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = datetime.now()\n",
    "UID = f\"{n.year:04d}{n.month:02d}{n.day:02d}-{n.hour:02d}{n.minute:02d}{n.second:02d}\"\n",
    "SEED = 20210309"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2021-03-09 22:25:51  INFO] 학습 시작\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "utils.seed_everything(SEED, deterministic=False)\n",
    "\n",
    "RESULT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "log = utils.CustomLogger(RESULT_DIR / f\"log_{UID}.log\", \"w\")\n",
    "log.info(\"학습 시작\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 데이터 로딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시간이 많지 않으니 box는 CrossValidation하지 않고, 대신 fold만 10개로 나눠줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs_ori = np.array(sorted(list(Path(\"data/ori/train_imgs/\").glob(\"*.jpg\"))))\n",
    "test_imgs = np.array(sorted(list(Path(\"data/ori/test_imgs/\").glob(\"*.jpg\"))))\n",
    "train_df = pd.read_csv(\"data/ori/train_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, valid_idx = next(kf.split(train_imgs_ori).__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = train_imgs_ori[train_idx]\n",
    "valid_imgs = train_imgs_ori[valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn = train_df.to_numpy()\n",
    "train_keypoints = dfn[train_idx, 1:].reshape(len(train_idx), -1, 2)\n",
    "valid_keypoints = dfn[valid_idx, 1:].reshape(len(valid_idx), -1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2021-03-09 22:25:51  INFO] train: (3775, 24, 2), valid: (420, 24, 2), test: 1600\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "log.info(f\"train: {train_keypoints.shape}, valid: {valid_keypoints.shape}, test: {len(test_imgs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train 3397, valid 378개, test 1600개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, files, keypoints=None, padding=40):\n",
    "        super().__init__()\n",
    "        self.files = files\n",
    "        self.keypoints = keypoints\n",
    "        self.padding = padding\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        f = self.files[idx]\n",
    "        img = imageio.imread(f)\n",
    "        x = torch.as_tensor(img, dtype=torch.float32).permute(2, 0, 1) / 255.0\n",
    "\n",
    "        if self.keypoints is not None:\n",
    "            keypoints = self.keypoints[idx]\n",
    "            xmin = keypoints[:, 0].min() - self.padding\n",
    "            xmax = keypoints[:, 0].max() + self.padding\n",
    "            ymin = keypoints[:, 1].min() - self.padding\n",
    "            ymax = keypoints[:, 1].max() + self.padding\n",
    "            target = {\n",
    "                \"labels\": torch.tensor([1], dtype=torch.int64),\n",
    "                \"boxes\": torch.tensor([[xmin, ymin, xmax, ymax]], dtype=torch.float32),\n",
    "            }\n",
    "            return x, target\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ImageDataset(train_imgs, train_keypoints)\n",
    "ds_valid = ImageDataset(valid_imgs, valid_keypoints)\n",
    "ds_test = ImageDataset(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data example:\n",
      " tensor([[[0.5686, 0.5647, 0.4863,  ..., 0.5529, 0.5529, 0.5529],\n",
      "         [0.5216, 0.4392, 0.3255,  ..., 0.5490, 0.5490, 0.5490],\n",
      "         [0.3725, 0.3020, 0.1804,  ..., 0.5529, 0.5529, 0.5490],\n",
      "         ...,\n",
      "         [0.9020, 0.9020, 0.9020,  ..., 0.6235, 0.6275, 0.6275],\n",
      "         [0.9020, 0.9020, 0.9020,  ..., 0.6275, 0.6275, 0.6275],\n",
      "         [0.9059, 0.9059, 0.9059,  ..., 0.6353, 0.6353, 0.6392]],\n",
      "\n",
      "        [[0.5843, 0.5765, 0.4980,  ..., 0.5294, 0.5294, 0.5294],\n",
      "         [0.5294, 0.4471, 0.3333,  ..., 0.5255, 0.5255, 0.5255],\n",
      "         [0.3765, 0.3059, 0.1804,  ..., 0.5294, 0.5294, 0.5255],\n",
      "         ...,\n",
      "         [0.8392, 0.8392, 0.8392,  ..., 0.6667, 0.6706, 0.6706],\n",
      "         [0.8392, 0.8392, 0.8392,  ..., 0.6706, 0.6706, 0.6706],\n",
      "         [0.8431, 0.8431, 0.8431,  ..., 0.6784, 0.6784, 0.6824]],\n",
      "\n",
      "        [[0.4941, 0.4941, 0.4235,  ..., 0.4039, 0.4039, 0.4039],\n",
      "         [0.4745, 0.3922, 0.2824,  ..., 0.4000, 0.4000, 0.4000],\n",
      "         [0.3569, 0.2863, 0.1725,  ..., 0.4039, 0.4039, 0.4000],\n",
      "         ...,\n",
      "         [0.7373, 0.7373, 0.7373,  ..., 0.6431, 0.6471, 0.6471],\n",
      "         [0.7373, 0.7373, 0.7373,  ..., 0.6471, 0.6471, 0.6471],\n",
      "         [0.7412, 0.7412, 0.7412,  ..., 0.6549, 0.6549, 0.6588]]]) \n",
      " {'labels': tensor([1]), 'boxes': tensor([[ 916.0000,  276.3117, 1174.0000,  878.8275]])}\n"
     ]
    }
   ],
   "source": [
    "print(\"data example:\\r\\n\", str(ds_train[0][0]), \"\\r\\n\", str(ds_train[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = lambda x: tuple(zip(*x))\n",
    "dl_train = DataLoader(ds_train, batch_size=BATCH_SIZE, num_workers=4, collate_fn=collate_fn, shuffle=True)\n",
    "dl_valid = DataLoader(ds_valid, batch_size=BATCH_SIZE, num_workers=4, collate_fn=collate_fn, shuffle=False)\n",
    "dl_test = DataLoader(ds_test, batch_size=BATCH_SIZE, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_model = fasterrcnn_resnet50_fpn(pretrained=True, progress=False).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(box_model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = ReduceLROnPlateau(optimizer, factor=0.5, patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dl: DataLoader):\n",
    "    torch.cuda.empty_cache()\n",
    "    box_model.train()\n",
    "\n",
    "    meanloss = utils.AverageMeter()\n",
    "    with tqdm(total=len(dl.dataset), ncols=100, leave=False, file=sys.stdout) as t:\n",
    "        for xs, ys in dl:\n",
    "            xs_ = [x.cuda() for x in xs]\n",
    "            ys_ = [{k: v.cuda() for k, v in y.items()} for y in ys]\n",
    "            losses = box_model(xs_, ys_)\n",
    "            loss = sum(loss for loss in losses.values())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            meanloss.update(loss.item())\n",
    "            t.set_postfix_str(f\"loss: {loss.item():.6f}\", refresh=False)\n",
    "            t.update(len(xs))\n",
    "\n",
    "    return meanloss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_loop(dl: DataLoader):\n",
    "    torch.cuda.empty_cache()\n",
    "    box_model.train()\n",
    "\n",
    "    meanloss = utils.AverageMeter()\n",
    "    with tqdm(total=len(dl.dataset), ncols=100, leave=False, file=sys.stdout) as t:\n",
    "        for xs, ys in dl:\n",
    "            xs_ = [x.cuda() for x in xs]\n",
    "            ys_ = [{k: v.cuda() for k, v in y.items()} for y in ys]\n",
    "            losses = box_model(xs_, ys_)\n",
    "            loss = sum(loss for loss in losses.values())\n",
    "\n",
    "            meanloss.update(loss.item())\n",
    "            t.set_postfix_str(f\"val_loss: {loss.item():.6f}\", refresh=False)\n",
    "            t.update(len(xs))\n",
    "\n",
    "    return meanloss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2021-03-09 22:31:10  INFO] Epoch: 001, loss: 0.026410 ; 0.017418\u001b[0m                          \n",
      "                                                                                                    \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-99f0efbc2e24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTART_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mvloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-a4f2298554c8>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dl)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mmeanloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"loss: {loss.item():.6f}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_loss = math.inf\n",
    "early_stop_cnt = 0\n",
    "\n",
    "for epoch in range(START_EPOCH, 999):\n",
    "    tloss = train_loop(dl_train)\n",
    "    vloss = valid_loop(dl_valid)\n",
    "    \n",
    "    # Logging\n",
    "    log.info(f'Epoch: {epoch:03d}, loss: {tloss:.6f} ; {vloss:.6f}')\n",
    "    scheduler.step(vloss)\n",
    "    \n",
    "    # Earlystop\n",
    "    if vloss < best_loss:\n",
    "        best_loss = vloss\n",
    "        early_stop_cnt = 0\n",
    "        \n",
    "        torch.save({\n",
    "            'model': box_model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'epoch': epoch\n",
    "        }, RESULT_DIR/f'ckpt-{UID}.pth')\n",
    "    elif early_stop_cnt >= 20:\n",
    "        log.info(f'Stop training at epoch {epoch}.')\n",
    "        break\n",
    "    else:\n",
    "        early_stop_cnt +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best ckpt 불러와서 ds_train, ds_valid 합쳐서 2epoch정도 더 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load(RESULT_DIR / f\"ckpt-{UID}.pth\")\n",
    "box_model.load_state_dict(ckpt[\"model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch의 ChainDataset이 shuffle이 안되서 그냥 직접 만들음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChainDataset(Dataset):\n",
    "    def __init__(self, *ds_list: Dataset):\n",
    "        \"\"\"\n",
    "        Combine multiple dataset into one.\n",
    "        Parameters\n",
    "        ----------\n",
    "        ds_list: list of datasets\n",
    "        \"\"\"\n",
    "        self.ds_list = ds_list\n",
    "        self.len_list = [len(ds) for ds in self.ds_list]\n",
    "        self.total_len = sum(self.len_list)\n",
    "\n",
    "        self.idx_list = []\n",
    "        for i, l in enumerate(self.len_list):\n",
    "            self.idx_list.extend([(i, j) for j in range(l)])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        didx, sidx = self.idx_list[idx]\n",
    "        return self.ds_list[didx][sidx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_total = ChainDataset(ds_train, ds_valid)\n",
    "dl_total = DataLoader(ds_total, batch_size=BATCH_SIZE, num_workers=4, collate_fn=collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-bf148b1eccb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_total\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-a4f2298554c8>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dl)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mmeanloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"loss: {loss.item():.6f}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loop(dl_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HRNet이 고정된 이미지 사이즈를 받는지를 우선 확인해보는게 먼저일듯?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
