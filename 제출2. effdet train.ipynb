{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mineral-moscow",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "legislative-smart",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from multiprocessing import cpu_count\n",
    "from pathlib import Path\n",
    "from pprint import pformat\n",
    "from typing import Iterable, List\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import yaml\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from easydict import EasyDict\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from torch import nn, optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from effdet_torch_singlefile import EfficientDet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "collect-demonstration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최정명님이 공유해주신 잘못된 데이터들\n",
    "error_list = [317, 869, 873, 877, 911, 1559, 1560, 1562, 1566, 1575]\n",
    "error_list += [1577, 1578, 1582, 1606, 1607, 1622, 1623, 1624, 1625]\n",
    "error_list += [1629, 3968, 4115, 4116, 4117, 4118, 4119, 4120, 4121]\n",
    "error_list += [4122, 4123, 4124, 4125, 4126, 4127, 4128, 4129, 4130]\n",
    "error_list += [4131, 4132, 4133, 4134, 4135, 4136, 4137, 4138, 4139]\n",
    "error_list += [4140, 4141, 4142, 4143, 4144, 4145, 4146, 4147, 4148]\n",
    "error_list += [4149, 4150, 4151, 4152, 4153, 4154, 4155, 4156, 4157]\n",
    "error_list += [4158, 4159, 4160, 4161, 4162, 4163, 4164, 4165, 4166]\n",
    "error_list += [4167, 4168, 4169, 4170, 4171, 4172, 4173, 4174, 4175]\n",
    "error_list += [4176, 4177, 4178, 4179, 4180, 4181, 4182, 4183, 4184]\n",
    "error_list += [4185, 4186, 4187, 4188, 4189, 4190, 4191, 4192, 4193, 4194]\n",
    "# 20210323 추가\n",
    "error_list += [1516, 1597, 2221, 2808, 2821, 3081, 3084, 3085, 3090, 3093, 3283, 3284]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "favorite-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed, deterministic=False):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = deterministic\n",
    "        torch.backends.cudnn.benchmark = not deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "realistic-evidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"\n",
    "    AverageMeter, referenced to https://dacon.io/competitions/official/235626/codeshare/1684\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.sum = 0\n",
    "        self.cnt = 0\n",
    "        self.avg = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        if n > 0:\n",
    "            self.sum += val * n\n",
    "            self.cnt += n\n",
    "            self.avg = self.sum / self.cnt\n",
    "\n",
    "    def get(self):\n",
    "        return self.avg\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-single",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "certified-commander",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keypoint2box(keypoint, padding=0):\n",
    "    return np.array(\n",
    "        [\n",
    "            keypoint[:, 0].min() - padding,\n",
    "            keypoint[:, 1].min() - padding,\n",
    "            keypoint[:, 0].max() + padding,\n",
    "            keypoint[:, 1].max() + padding,\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "medieval-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HorizontalFlipEx(A.HorizontalFlip):\n",
    "    swap_columns = [(1, 2), (3, 4), (5, 6), (7, 8), (9, 10), (11, 12), (13, 14), (15, 16), (18, 19), (22, 23)]\n",
    "\n",
    "    def apply_to_keypoints(self, keypoints, **params):\n",
    "        keypoints = super().apply_to_keypoints(keypoints, **params)\n",
    "\n",
    "        # left/right 키포인트들은 서로 swap해주기\n",
    "        for a, b in self.swap_columns:\n",
    "            temp1 = deepcopy(keypoints[a])\n",
    "            temp2 = deepcopy(keypoints[b])\n",
    "            keypoints[a] = temp2\n",
    "            keypoints[b] = temp1\n",
    "\n",
    "        return keypoints\n",
    "\n",
    "\n",
    "class VerticalFlipEx(A.VerticalFlip):\n",
    "    swap_columns = [(1, 2), (3, 4), (5, 6), (7, 8), (9, 10), (11, 12), (13, 14), (15, 16), (18, 19), (22, 23)]\n",
    "\n",
    "    def apply_to_keypoints(self, keypoints, **params):\n",
    "        keypoints = super().apply_to_keypoints(keypoints, **params)\n",
    "\n",
    "        # left/right 키포인트들은 서로 swap해주기\n",
    "        for a, b in self.swap_columns:\n",
    "            temp1 = deepcopy(keypoints[a])\n",
    "            temp2 = deepcopy(keypoints[b])\n",
    "            keypoints[a] = temp2\n",
    "            keypoints[b] = temp1\n",
    "\n",
    "        return keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "helpful-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetDataset(Dataset):\n",
    "    def __init__(self, config, files, keypoints, augmentation):\n",
    "        super().__init__()\n",
    "        self.C = config\n",
    "        self.files = files\n",
    "        self.keypoints = keypoints\n",
    "\n",
    "        T = []\n",
    "        T.append(A.Crop(*self.C.dataset.crop))\n",
    "        T.append(A.Resize(self.C.dataset.input_height, self.C.dataset.input_width))\n",
    "        if augmentation:\n",
    "            T_ = []\n",
    "            T_.append(A.Cutout(num_holes=16, max_h_size=100, max_w_size=100, fill_value=0, p=1))\n",
    "            T_.append(A.Cutout(num_holes=16, max_h_size=100, max_w_size=100, fill_value=255, p=1))\n",
    "            T_.append(A.Cutout(num_holes=16, max_h_size=100, max_w_size=100, fill_value=128, p=1))\n",
    "            T_.append(A.Cutout(num_holes=16, max_h_size=100, max_w_size=100, fill_value=192, p=1))\n",
    "            T_.append(A.Cutout(num_holes=16, max_h_size=100, max_w_size=100, fill_value=64, p=1))\n",
    "            T_.append(A.Cutout(num_holes=5, max_h_size=1920, max_w_size=50, fill_value=0, p=1))\n",
    "            T_.append(A.Cutout(num_holes=5, max_h_size=1920, max_w_size=50, fill_value=255, p=1))\n",
    "            T_.append(A.Cutout(num_holes=5, max_h_size=1920, max_w_size=50, fill_value=128, p=1))\n",
    "            T_.append(A.Cutout(num_holes=5, max_h_size=1920, max_w_size=50, fill_value=192, p=1))\n",
    "            T_.append(A.Cutout(num_holes=5, max_h_size=1920, max_w_size=50, fill_value=64, p=1))\n",
    "            T_.append(A.Cutout(num_holes=5, max_h_size=30, max_w_size=1080, fill_value=0, p=1))\n",
    "            T_.append(A.Cutout(num_holes=5, max_h_size=30, max_w_size=1080, fill_value=255, p=1))\n",
    "            T_.append(A.Cutout(num_holes=5, max_h_size=30, max_w_size=1080, fill_value=128, p=1))\n",
    "            T_.append(A.Cutout(num_holes=5, max_h_size=30, max_w_size=1080, fill_value=192, p=1))\n",
    "            T_.append(A.Cutout(num_holes=5, max_h_size=30, max_w_size=1080, fill_value=64, p=1))\n",
    "            # T_.append(A.Cutout(max_h_size=20, max_w_size=20))\n",
    "            # T_.append(A.Cutout(max_h_size=20, max_w_size=20, fill_value=255))\n",
    "            # T_.append(A.Cutout(max_h_size=self.C.dataset.input_height // 2, max_w_size=10, fill_value=255))\n",
    "            # T_.append(A.Cutout(max_h_size=self.C.dataset.input_height // 2, max_w_size=10, fill_value=0))\n",
    "            # T_.append(A.Cutout(max_h_size=10, max_w_size=self.C.dataset.input_width // 2, fill_value=255))\n",
    "            # T_.append(A.Cutout(max_h_size=10, max_w_size=self.C.dataset.input_width // 2, fill_value=0))\n",
    "            T.append(A.OneOf(T_))\n",
    "\n",
    "            T.append(A.ShiftScaleRotate(border_mode=cv2.BORDER_CONSTANT))\n",
    "            T.append(HorizontalFlipEx())\n",
    "            T.append(VerticalFlipEx())\n",
    "            # T.append(A.RandomRotate90()) # batch-augmentation으로 대체\n",
    "\n",
    "            T_ = []\n",
    "            T_.append(A.RandomBrightnessContrast())\n",
    "            T_.append(A.RandomGamma())\n",
    "            T_.append(A.RandomBrightness())\n",
    "            T_.append(A.RandomContrast())\n",
    "            T.append(A.OneOf(T_))\n",
    "\n",
    "            T_ = []\n",
    "            T_.append(A.MotionBlur(p=1))\n",
    "            T_.append(A.GaussNoise(p=1))\n",
    "            T.append(A.OneOf(T_))\n",
    "        T.append(A.Normalize())\n",
    "        T.append(ToTensorV2())\n",
    "\n",
    "        self.transform = A.Compose(\n",
    "            transforms=T,\n",
    "            bbox_params=A.BboxParams(format=\"pascal_voc\", label_fields=[\"labels\"]),\n",
    "            # keypoint_params=A.KeypointParams(format=\"xy\", remove_invisible=False),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = str(self.files[idx])\n",
    "        image = imageio.imread(file)\n",
    "\n",
    "        keypoint = self.keypoints[idx]\n",
    "        box = keypoint2box(keypoint, self.C.dataset.padding)\n",
    "        box = np.expand_dims(box, 0)\n",
    "        labels = np.array([0], dtype=np.int64)\n",
    "        a = self.transform(image=image, labels=labels, bboxes=box)\n",
    "\n",
    "        image = a[\"image\"]\n",
    "\n",
    "        annot = np.zeros((1, 5), dtype=np.float32)\n",
    "        annot[0, :4] = a[\"bboxes\"][0]\n",
    "        annot = torch.tensor(annot, dtype=torch.float32)\n",
    "\n",
    "        return file, image, annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adolescent-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_det_dataset(C, fold):\n",
    "    datadir = Path(C.dataset.dir)\n",
    "    total_imgs = np.array(sorted(list((datadir / \"train_imgs\").glob(\"*.jpg\"))))\n",
    "    df = pd.read_csv(datadir / \"train_df.csv\")\n",
    "    total_keypoints = df.to_numpy()[:, 1:].astype(np.float32)\n",
    "    total_keypoints = np.stack([total_keypoints[:, 0::2], total_keypoints[:, 1::2]], axis=2)\n",
    "\n",
    "    # 오류가 있는 데이터는 학습에서 제외\n",
    "    total_imgs_, total_keypoints_ = [], []\n",
    "    for i in range(len(total_imgs)):\n",
    "        if i not in error_list:\n",
    "            total_imgs_.append(total_imgs[i])\n",
    "            total_keypoints_.append(total_keypoints[i])\n",
    "    total_imgs = np.array(total_imgs_)\n",
    "    total_keypoints = np.array(total_keypoints_)\n",
    "\n",
    "    # KFold\n",
    "    if C.dataset.group_kfold:\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=C.seed)\n",
    "        # 파일 이름 앞 17자리를 group으로 이미지를 분류 (파일이 너무 잘 섞여도 안됨)\n",
    "        groups = []\n",
    "        last_group = 0\n",
    "        last_stem = total_imgs[0].name[:17]\n",
    "        for f in total_imgs:\n",
    "            stem = f.name[:17]\n",
    "            if stem == last_stem:\n",
    "                groups.append(last_group)\n",
    "            else:\n",
    "                last_group += 1\n",
    "                last_stem = stem\n",
    "                groups.append(last_group)\n",
    "        indices = list(skf.split(total_imgs, groups))\n",
    "    else:\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=C.seed)\n",
    "        indices = list(kf.split(total_imgs))\n",
    "    train_idx, valid_idx = indices[fold - 1]\n",
    "\n",
    "    # 데이터셋 생성\n",
    "    ds_train = DetDataset(\n",
    "        C,\n",
    "        total_imgs[train_idx],\n",
    "        total_keypoints[train_idx],\n",
    "        augmentation=True,\n",
    "    )\n",
    "    ds_valid = DetDataset(\n",
    "        C,\n",
    "        total_imgs[valid_idx],\n",
    "        total_keypoints[valid_idx],\n",
    "        augmentation=False,\n",
    "    )\n",
    "    dl_train = DataLoader(\n",
    "        ds_train,\n",
    "        batch_size=C.dataset.batch_size,\n",
    "        num_workers=C.dataset.num_cpus,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    dl_valid = DataLoader(\n",
    "        ds_valid,\n",
    "        batch_size=C.dataset.batch_size,\n",
    "        num_workers=C.dataset.num_cpus,\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    return dl_train, dl_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-words",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fantastic-turkish",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetTrainOutput:\n",
    "    def __init__(self):\n",
    "        self.loss = AverageMeter()\n",
    "\n",
    "    def freeze(self):\n",
    "        self.loss = self.loss()\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "connected-sunset",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetTrainer:\n",
    "    _tqdm_ = dict(ncols=100, leave=False, file=sys.stdout)\n",
    "\n",
    "    def __init__(self, C, fold=1, checkpoint=None):\n",
    "        self.C = C\n",
    "        self.fold = fold\n",
    "\n",
    "        self.det_model = EfficientDet(self.C.det_model.name, pretrained=True)\n",
    "        self.det_model.cuda()\n",
    "\n",
    "        # Optimizer\n",
    "        self.optimizer = optim.AdamW(self.det_model.parameters(), lr=self.C.train.lr)\n",
    "\n",
    "        self.epoch = self.C.train.start_epoch\n",
    "        self.best_loss = math.inf\n",
    "        self.earlystop_cnt = 0\n",
    "\n",
    "        # Dataset\n",
    "        self.dl_train, self.dl_valid = get_det_dataset(C, self.fold)\n",
    "\n",
    "        # Load Checkpoint\n",
    "        if checkpoint is not None:\n",
    "            self.load(checkpoint)\n",
    "\n",
    "        # Scheduler\n",
    "        self.scheduler = lr_scheduler.ReduceLROnPlateau(self.optimizer, **self.C.train.scheduler.params)\n",
    "\n",
    "    def save(self, path):\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model\": self.det_model.state_dict(),\n",
    "                \"optimizer\": self.optimizer.state_dict(),\n",
    "                \"epoch\": self.epoch,\n",
    "                \"best_loss\": self.best_loss,\n",
    "                \"earlystop_cnt\": self.earlystop_cnt,\n",
    "            },\n",
    "            path,\n",
    "        )\n",
    "\n",
    "    def load(self, path):\n",
    "        print(\"Load pretrained\", path)\n",
    "        ckpt = torch.load(path)\n",
    "        self.det_model.load_state_dict(ckpt[\"model\"])\n",
    "        self.optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
    "        self.epoch = ckpt[\"epoch\"] + 1\n",
    "        self.best_loss = ckpt[\"best_loss\"]\n",
    "        self.earlystop_cnt = ckpt[\"earlystop_cnt\"]\n",
    "\n",
    "    def train_loop(self):\n",
    "        self.det_model.train()\n",
    "\n",
    "        O = DetTrainOutput()\n",
    "        with tqdm(total=len(self.dl_train.dataset), **self._tqdm_, desc=f\"Train {self.epoch:03d}\") as t:\n",
    "            for files, imgs, annots in self.dl_train:\n",
    "                imgs_, annots_ = imgs.cuda(non_blocking=True), annots.cuda(non_blocking=True)\n",
    "\n",
    "                # batch augmentation\n",
    "                if self.C.train.batch_augmentation:\n",
    "                    h, w = imgs.shape[2:]\n",
    "\n",
    "                    # downsample\n",
    "                    if random.random() <= 0.5:\n",
    "                        imgs_ = F.interpolate(imgs_, (h // 2, w // 2))\n",
    "                        annots_[..., :4] *= 0.5\n",
    "\n",
    "                    # rotation\n",
    "                    if random.random() <= 0.5:\n",
    "                        k = random.randint(1, 3)\n",
    "                        a, b, c, d = annots_[..., 0], annots_[..., 1], annots_[..., 2], annots_[..., 3]\n",
    "                        e = annots_[..., 4]\n",
    "                        if k == 1:\n",
    "                            annots_ = torch.stack([b, w - c, d, w - a, e], dim=2)\n",
    "                        elif k == 2:\n",
    "                            annots_ = torch.stack([w - c, h - d, w - a, h - b, e], dim=2)\n",
    "                        elif k == 3:\n",
    "                            annots_ = torch.stack([h - d, a, h - b, c, e], dim=2)\n",
    "                        imgs_ = torch.rot90(imgs_, k=k, dims=(2, 3))\n",
    "\n",
    "                loss = self.det_model(imgs_, annots_)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                O.loss.update(loss.item(), len(files))\n",
    "                t.set_postfix_str(f\"loss: {loss.item():.6f}\", refresh=False)\n",
    "                t.update(len(files))\n",
    "\n",
    "        return O.freeze()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def valid_loop(self):\n",
    "        self.det_model.eval()\n",
    "\n",
    "        O = DetTrainOutput()\n",
    "        with tqdm(total=len(self.dl_valid.dataset), **self._tqdm_, desc=f\"Valid {self.epoch:03d}\") as t:\n",
    "            for files, imgs, annots in self.dl_valid:\n",
    "                imgs_, annots_ = imgs.cuda(non_blocking=True), annots.cuda(non_blocking=True)\n",
    "                loss = self.det_model(imgs_, annots_)\n",
    "\n",
    "                O.loss.update(loss.item(), len(files))\n",
    "                t.set_postfix_str(f\"loss: {loss.item():.6f}\", refresh=False)\n",
    "                t.update(len(files))\n",
    "\n",
    "        return O.freeze()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def callback(self, to: DetTrainOutput, vo: DetTrainOutput):\n",
    "        print(\n",
    "            f\"Epoch: {self.epoch:03d},\",\n",
    "            f\"loss: {to.loss:.6f};{vo.loss:.6f},\",\n",
    "        )\n",
    "\n",
    "        self.scheduler.step(vo.loss)\n",
    "\n",
    "        if self.best_loss > vo.loss:\n",
    "            self.best_loss = vo.loss\n",
    "            self.earlystop_cnt = 0\n",
    "            self.save(self.C.result_dir / f\"effdet_d7_{self.fold}.pth\")\n",
    "        else:\n",
    "            self.earlystop_cnt += 1\n",
    "\n",
    "    def fit(self):\n",
    "        for self.epoch in range(self.epoch, self.C.train.final_epoch + 1):\n",
    "            to = self.train_loop()\n",
    "            vo = self.valid_loop()\n",
    "            self.callback(to, vo)\n",
    "\n",
    "            if self.earlystop_cnt > self.C.train.earlystop_patience:\n",
    "                print(f\"Stop training at epoch\", self.epoch)\n",
    "                break\n",
    "\n",
    "        self.load(self.C.result_dir / f\"effdet_d7_{self.fold}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "soviet-watershed",
   "metadata": {},
   "outputs": [],
   "source": [
    "__effdet_train_config__ = \"\"\"\n",
    "seed: 20210309\n",
    "result_dir: results/submit\n",
    "\n",
    "det_model: \n",
    "  name: efficientdet-d7\n",
    "\n",
    "dataset:\n",
    "  dir: data/ori\n",
    "  batch_size: 2\n",
    "  num_cpus: 1\n",
    "  padding: 20\n",
    "  group_kfold: false\n",
    "  \n",
    "  crop:\n",
    "    - 192\n",
    "    - 28\n",
    "    - 1728\n",
    "    - 1052\n",
    "\n",
    "  input_width: 768 # 1536\n",
    "  input_height: 512 # 1024\n",
    "  \n",
    "train:\n",
    "  earlystop_patience: 10\n",
    "  start_epoch: 1\n",
    "  final_epoch: 200\n",
    "  \n",
    "  batch_augmentation: true\n",
    "  \n",
    "  folds:\n",
    "    - 1\n",
    "  checkpoints:\n",
    "    - null\n",
    "\n",
    "  lr: 0.0001\n",
    "  scheduler:\n",
    "    type: ReduceLROnPlateau\n",
    "    params:\n",
    "      factor: 0.5\n",
    "      patience: 3\n",
    "      verbose: true\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "headed-charge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    C = EasyDict(yaml.load(__effdet_train_config__, yaml.FullLoader))\n",
    "    fold, checkpoint = C.train.folds[0], C.train.checkpoints[0]\n",
    "\n",
    "    Path(C.result_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if C.dataset.num_cpus < 0:\n",
    "        C.dataset.num_cpus = cpu_count()\n",
    "\n",
    "    C.result_dir = Path(C.result_dir)\n",
    "    C.dataset.dir = Path(C.dataset.dir)\n",
    "    seed_everything(C.seed)\n",
    "\n",
    "    trainer = DetTrainer(C, fold, checkpoint)\n",
    "    trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "amino-static",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained /home/shim/.cache/torch/hub/checkpoints/efficientdet-d7.pth\n",
      "Epoch: 001, loss: 1.361526;7.025075,                                                                \n",
      "Epoch: 002, loss: 1.022509;0.988709,                                                                \n",
      "Epoch: 003, loss: 0.898137;0.444924,                                                                \n",
      "Epoch: 004, loss: 0.844895;6.050953,                                                                \n",
      "Epoch: 005, loss: 0.799611;0.751952,                                                                \n",
      "Epoch: 006, loss: 0.773905;1.220256,                                                                \n",
      "Epoch: 007, loss: 0.745828;3.228482,                                                                \n",
      "Epoch     7: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Epoch: 008, loss: 0.552989;0.869062,                                                                \n",
      "Epoch: 009, loss: 0.519843;0.859280,                                                                \n",
      "Epoch: 010, loss: 0.506348;0.237791,                                                                \n",
      "Load pretrained results/submit/effdet_d7_1.pth\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-evening",
   "metadata": {},
   "source": [
    "10epoch만 학습 해봤습니다. 학습 로그는 아래와 같습니다.\n",
    "\n",
    "```log\n",
    "[2021-04-04 23:09:27  INFO] Epoch: 001, loss: 1.345929;0.607354,\n",
    "[2021-04-04 23:18:55  INFO] Epoch: 002, loss: 1.032379;0.974972,\n",
    "[2021-04-04 23:28:11  INFO] Epoch: 003, loss: 0.899945;0.447793,\n",
    "[2021-04-04 23:37:33  INFO] Epoch: 004, loss: 0.831420;0.583468,\n",
    "[2021-04-04 23:46:44  INFO] Epoch: 005, loss: 0.799242;1.710531,\n",
    "[2021-04-04 23:56:01  INFO] Epoch: 006, loss: 0.755635;0.422747,\n",
    "[2021-04-05 00:05:15  INFO] Epoch: 007, loss: 0.761829;0.480131,\n",
    "[2021-04-05 00:14:30  INFO] Epoch: 008, loss: 0.680230;2.825914,\n",
    "[2021-04-05 00:23:47  INFO] Epoch: 009, loss: 0.699145;2.252932,\n",
    "[2021-04-05 00:33:00  INFO] Epoch: 010, loss: 0.668748;0.433503,\n",
    "[2021-04-05 00:42:16  INFO] Epoch: 011, loss: 0.559386;0.215368,\n",
    "[2021-04-05 00:51:32  INFO] Epoch: 012, loss: 0.500916;0.258114,\n",
    "[2021-04-05 01:00:47  INFO] Epoch: 013, loss: 0.483150;0.247860,\n",
    "[2021-04-05 01:09:58  INFO] Epoch: 014, loss: 0.458754;0.172292,\n",
    "[2021-04-05 01:19:22  INFO] Epoch: 015, loss: 0.432042;0.156415,\n",
    "[2021-04-05 01:28:40  INFO] Epoch: 016, loss: 0.423682;0.172074,\n",
    "[2021-04-05 01:38:07  INFO] Epoch: 017, loss: 0.419228;0.227202,\n",
    "[2021-04-05 01:47:17  INFO] Epoch: 018, loss: 0.426307;0.202776,\n",
    "[2021-04-05 01:56:38  INFO] Epoch: 019, loss: 0.422774;0.183640,\n",
    "[2021-04-05 02:05:52  INFO] Epoch: 020, loss: 0.356231;0.131375,\n",
    "[2021-04-05 02:15:05  INFO] Epoch: 021, loss: 0.325380;0.121130,\n",
    "[2021-04-05 02:24:25  INFO] Epoch: 022, loss: 0.334707;0.121304,\n",
    "[2021-04-05 02:33:40  INFO] Epoch: 023, loss: 0.315013;0.123282,\n",
    "[2021-04-05 02:43:00  INFO] Epoch: 024, loss: 0.308335;0.137350,\n",
    "[2021-04-05 02:52:19  INFO] Epoch: 025, loss: 0.316076;0.106638,\n",
    "[2021-04-05 03:01:39  INFO] Epoch: 026, loss: 0.303245;0.103056,\n",
    "[2021-04-05 03:10:51  INFO] Epoch: 027, loss: 0.301873;0.114936,\n",
    "[2021-04-05 03:20:15  INFO] Epoch: 028, loss: 0.307543;0.114505,\n",
    "[2021-04-05 03:29:34  INFO] Epoch: 029, loss: 0.298067;0.109576,\n",
    "[2021-04-05 03:38:48  INFO] Epoch: 030, loss: 0.294818;0.132326,\n",
    "[2021-04-05 03:48:07  INFO] Epoch: 031, loss: 0.275761;0.088775,\n",
    "[2021-04-05 03:57:28  INFO] Epoch: 032, loss: 0.264910;0.097282,\n",
    "[2021-04-05 04:06:49  INFO] Epoch: 033, loss: 0.265827;0.094159,\n",
    "[2021-04-05 04:16:11  INFO] Epoch: 034, loss: 0.253544;0.103739,\n",
    "[2021-04-05 04:25:28  INFO] Epoch: 035, loss: 0.264441;0.090745,\n",
    "[2021-04-05 04:34:50  INFO] Epoch: 036, loss: 0.250116;0.080270,\n",
    "[2021-04-05 04:44:12  INFO] Epoch: 037, loss: 0.248722;0.090331,\n",
    "[2021-04-05 04:53:26  INFO] Epoch: 038, loss: 0.243801;0.083525,\n",
    "[2021-04-05 05:02:41  INFO] Epoch: 039, loss: 0.229252;0.083217,\n",
    "[2021-04-05 05:12:03  INFO] Epoch: 040, loss: 0.227173;0.093092,\n",
    "[2021-04-05 05:21:16  INFO] Epoch: 041, loss: 0.233974;0.078002,\n",
    "[2021-04-05 05:30:35  INFO] Epoch: 042, loss: 0.224974;0.077236,\n",
    "[2021-04-05 05:39:51  INFO] Epoch: 043, loss: 0.239731;0.077556,\n",
    "[2021-04-05 05:49:09  INFO] Epoch: 044, loss: 0.231345;0.077701,\n",
    "[2021-04-05 05:58:28  INFO] Epoch: 045, loss: 0.222928;0.079066,\n",
    "[2021-04-05 06:07:48  INFO] Epoch: 046, loss: 0.229059;0.085703,\n",
    "[2021-04-05 06:17:01  INFO] Epoch: 047, loss: 0.238931;0.079773,\n",
    "[2021-04-05 06:26:27  INFO] Epoch: 048, loss: 0.233236;0.077964,\n",
    "[2021-04-05 06:35:47  INFO] Epoch: 049, loss: 0.231080;0.079676,\n",
    "[2021-04-05 06:45:00  INFO] Epoch: 050, loss: 0.225975;0.077771,\n",
    "[2021-04-05 06:54:25  INFO] Epoch: 051, loss: 0.226893;0.070260,\n",
    "[2021-04-05 07:03:43  INFO] Epoch: 052, loss: 0.241337;0.075432,\n",
    "[2021-04-05 07:13:05  INFO] Epoch: 053, loss: 0.226088;0.071070,\n",
    "[2021-04-05 07:22:24  INFO] Epoch: 054, loss: 0.222690;0.075063,\n",
    "[2021-04-05 07:31:41  INFO] Epoch: 055, loss: 0.226015;0.076678,\n",
    "[2021-04-05 07:40:57  INFO] Epoch: 056, loss: 0.228466;0.081537,\n",
    "[2021-04-05 07:50:20  INFO] Epoch: 057, loss: 0.220756;0.076941,\n",
    "[2021-04-05 07:59:38  INFO] Epoch: 058, loss: 0.225289;0.075737,\n",
    "[2021-04-05 08:08:54  INFO] Epoch: 059, loss: 0.233874;0.073094,\n",
    "[2021-04-05 08:18:13  INFO] Epoch: 060, loss: 0.211533;0.076971,\n",
    "[2021-04-05 08:27:30  INFO] Epoch: 061, loss: 0.220242;0.077371,\n",
    "[2021-04-05 08:36:49  INFO] Epoch: 062, loss: 0.220992;0.071223,\n",
    "[2021-04-05 08:36:49  INFO] Stop training at epoch 62\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-israeli",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
