{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from io import TextIOWrapper\n",
    "from pathlib import Path\n",
    "from typing import Callable, List, Sequence, Tuple\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.model_selection import KFold\n",
    "from torch import nn, optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.dataset import Subset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.models import mobilenet_v2\n",
    "from torchvision.models.detection import KeypointRCNN, keypointrcnn_resnet50_fpn\n",
    "from torchvision.ops import MultiScaleRoIAlign\n",
    "from tqdm import tqdm\n",
    "\n",
    "import utils\n",
    "\n",
    "BASELINE = True\n",
    "MODEL = \"keypointrcnn_resnet50_fpn_finetune_step1\"\n",
    "DATA_DIR = Path(\"data/ori\")\n",
    "FOLD = 1\n",
    "START_EPOCH = 1\n",
    "NUM_EPOCHS = 200\n",
    "N_TTA_TEST = 10\n",
    "N_TTA_VALID = 1\n",
    "SAM = False\n",
    "LR = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeypointDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_dir: os.PathLike,\n",
    "        label_path: os.PathLike,\n",
    "        transforms: Sequence[Callable] = None,\n",
    "    ) -> None:\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.df = pd.read_csv(label_path).to_numpy()\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        image_id = self.df[index, 0]\n",
    "        labels = np.array([1])\n",
    "        # int64가 아니면 안되는건가? 소숫점이 손실될텐데?\n",
    "        keypoints = self.df[index, 1:].reshape(-1, 2).astype(np.int64)\n",
    "\n",
    "        x1, y1 = min(keypoints[:, 0]), min(keypoints[:, 1])\n",
    "        x2, y2 = max(keypoints[:, 0]), max(keypoints[:, 1])\n",
    "        boxes = np.array([[x1, y1, x2, y2]], dtype=np.int64)\n",
    "\n",
    "        image = cv2.imread(str(self.image_dir / image_id), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        targets = {\n",
    "            \"image\": image,\n",
    "            \"bboxes\": boxes,\n",
    "            \"labels\": labels,\n",
    "            \"keypoints\": keypoints,\n",
    "        }\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            targets = self.transforms(**targets)\n",
    "\n",
    "        image = targets[\"image\"]\n",
    "        image = image / 255.0\n",
    "\n",
    "        targets = {\n",
    "            \"labels\": torch.as_tensor(targets[\"labels\"], dtype=torch.int64),\n",
    "            \"boxes\": torch.as_tensor(targets[\"bboxes\"], dtype=torch.float32),\n",
    "            \"keypoints\": torch.as_tensor(\n",
    "                np.concatenate([targets[\"keypoints\"], np.ones((24, 1))], axis=1)[np.newaxis],\n",
    "                dtype=torch.float32,\n",
    "            ),\n",
    "        }\n",
    "\n",
    "        return image, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch: torch.Tensor) -> Tuple:\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\n",
    "def load_dataset(fold):\n",
    "    transform = A.Compose(\n",
    "        [\n",
    "            A.Resize(800, 1333),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "        bbox_params=A.BboxParams(format=\"pascal_voc\", label_fields=[\"labels\"]),\n",
    "        keypoint_params=A.KeypointParams(format=\"xy\"),\n",
    "    )\n",
    "\n",
    "    ds = KeypointDataset(DATA_DIR / \"train_imgs\", DATA_DIR / \"train_df.csv\", transform)\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=1351235)\n",
    "    for i, (tidx, vidx) in enumerate(kf.split(ds), 1):\n",
    "        if i == fold:\n",
    "            if BASELINE:\n",
    "                tidx = tidx[: len(tidx) // 10]\n",
    "                vidx = vidx[: len(vidx) // 10]\n",
    "\n",
    "            tds, vds = Subset(ds, tidx), Subset(ds, vidx)\n",
    "            tdl = DataLoader(tds, batch_size=24, shuffle=True, num_workers=8, pin_memory=True, collate_fn=collate_fn)\n",
    "            vdl = DataLoader(vds, batch_size=24, shuffle=False, num_workers=8, pin_memory=True, collate_fn=collate_fn)\n",
    "            return tdl, vdl\n",
    "\n",
    "    raise NotImplementedError(\"out of folds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model() -> nn.Module:\n",
    "    if MODEL == \"우주대마왕\":\n",
    "        backbone = mobilenet_v2(pretrained=True).features\n",
    "        backbone.out_channels = 1280\n",
    "        roi_pooler = MultiScaleRoIAlign(featmap_names=[\"0\"], output_size=7, sampling_ratio=2)\n",
    "\n",
    "        keypoint_roi_pooler = MultiScaleRoIAlign(featmap_names=[\"0\"], output_size=14, sampling_ratio=2)\n",
    "\n",
    "        model = KeypointRCNN(\n",
    "            backbone,\n",
    "            num_classes=2,\n",
    "            num_keypoints=24,\n",
    "            box_roi_pool=roi_pooler,\n",
    "            keypoint_roi_pool=keypoint_roi_pooler,\n",
    "        )\n",
    "    elif MODEL == \"keypointrcnn_resnet50_fpn_finetune_step1\":\n",
    "        model = keypointrcnn_resnet50_fpn(pretrained=True, progress=False)\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        m = nn.ConvTranspose2d(512, 24, 4, 2, 1)\n",
    "        with torch.no_grad():\n",
    "            m.weight[:, :17] = model.roi_heads.keypoint_predictor.kps_score_lowres.weight\n",
    "            m.bias[:17] = model.roi_heads.keypoint_predictor.kps_score_lowres.bias\n",
    "            # m.weight = m.weight.contiguous()\n",
    "            # m.bias = m.bias.contiguous()\n",
    "        model.roi_heads.keypoint_predictor.kps_score_lowres = m\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    return model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdl, vdl = load_dataset(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = next(tdl.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_ = [x.cuda() for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_ = [{k: v.cuda() for k, v in y.items()} for y in ys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = model(xs_, ys_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss_classifier': tensor(0.1179, device='cuda:0'),\n",
       " 'loss_box_reg': tensor(0.0427, device='cuda:0'),\n",
       " 'loss_keypoint': tensor(8.0383, device='cuda:0', grad_fn=<NllLossBackward>),\n",
       " 'loss_objectness': tensor(0.2116, device='cuda:0'),\n",
       " 'loss_rpn_box_reg': tensor(0.0155, device='cuda:0')}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([tensor(0.1179, device='cuda:0'), tensor(0.0427, device='cuda:0'), tensor(8.0383, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.2116, device='cuda:0'), tensor(0.0155, device='cuda:0')])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "values의 sum 말고 중요한 요소만 집는 방법도 있을 것 같은데"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f80fd190a50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = model(xs_, ys_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boxes': tensor([], device='cuda:0', size=(0, 4)),\n",
       " 'labels': tensor([], device='cuda:0', dtype=torch.int64),\n",
       " 'scores': tensor([], device='cuda:0'),\n",
       " 'keypoints': tensor([], device='cuda:0', size=(0, 24, 3)),\n",
       " 'keypoints_scores': tensor([], device='cuda:0', size=(0, 24))}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
