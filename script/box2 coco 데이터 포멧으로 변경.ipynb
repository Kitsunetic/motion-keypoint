{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COCO 데이터 포멧으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from io import TextIOWrapper\n",
    "from pathlib import Path\n",
    "from typing import Callable, List, Sequence, Tuple\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.model_selection import KFold\n",
    "from torch import nn, optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from tqdm import tqdm\n",
    "\n",
    "import utils\n",
    "import networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_box = json.load(open(\"data/box2/offset.json\"))[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image': '001-1-1-01-Z17_A-0000001.jpg', 'boxes': [917, 282, 1174, 881]},\n",
       " {'image': '001-1-1-01-Z17_A-0000003.jpg', 'boxes': [932, 281, 1183, 882]}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_box[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {\"images\": [], \"annotations\": [], \"categories\": [{\"id\": 1, \"name\": \"person\"}]}\n",
    "for i, raw in enumerate(train_box):\n",
    "    result[\"images\"].append(\n",
    "        {\n",
    "            \"file_name\": raw[\"image\"],\n",
    "            \"filename\": raw[\"image\"],\n",
    "            \"height\": 1080,\n",
    "            \"width\": 1920,\n",
    "            \"id\": i,\n",
    "            \"ann\": [\n",
    "                {\n",
    "                    \"bboxes\": raw[\"boxes\"],\n",
    "                    \"labels\": [1],\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "    result[\"annotations\"].append(\n",
    "        {\n",
    "            \"bbox\": raw[\"boxes\"],\n",
    "            \"image_id\": i,\n",
    "            \"category_id\": 1,\n",
    "            \"id\": i,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_name': '001-1-1-01-Z17_A-0000001.jpg',\n",
       "  'filename': '001-1-1-01-Z17_A-0000001.jpg',\n",
       "  'height': 1080,\n",
       "  'width': 1920,\n",
       "  'id': 0,\n",
       "  'ann': [{'bboxes': [917, 282, 1174, 881], 'labels': [1]}]},\n",
       " {'file_name': '001-1-1-01-Z17_A-0000003.jpg',\n",
       "  'filename': '001-1-1-01-Z17_A-0000003.jpg',\n",
       "  'height': 1080,\n",
       "  'width': 1920,\n",
       "  'id': 1,\n",
       "  'ann': [{'bboxes': [932, 281, 1183, 882], 'labels': [1]}]}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"images\"][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(result, open(\"data/box2_coco2.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i, raw in enumerate(train_box):\n",
    "    result.append(\n",
    "        {\n",
    "            \"file_name\": raw[\"image\"],\n",
    "            \"filename\": raw[\"image\"],\n",
    "            \"height\": 1080,\n",
    "            \"width\": 1920,\n",
    "            \"id\": i,\n",
    "            \"ann\": {\n",
    "                \"bboxes\": [raw[\"boxes\"]],\n",
    "                \"labels\": [1],\n",
    "            },\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(result, open(\"data/box2_coco4.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
