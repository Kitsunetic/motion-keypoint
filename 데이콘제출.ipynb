{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- github 링크\n",
    "- 의존 라이브러리들 직접 사용으로 바꾸기\n",
    "- 로그파일 내용 출력해주기\n",
    "- EfficientDetFinetune은 직접사용으로 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "베이스라인 코드를 공유해주신 우주대마왕님께 감사드립니다.  \n",
    "디텍션 문제는 처음 접해봤음에도, 우주대마왕님의 코드를 보고 mask-rcnn부터 하나씩 시도해보면서 점수를 높일 수 있었습니다.\n",
    "\n",
    "### Summary\n",
    "\n",
    "주로 사용된 기법은 아래와 같습니다.\n",
    "\n",
    "- Efficientdet-d7\n",
    "- HRNet-W48\n",
    "- 5 fold cross validation\n",
    "- test-time augmentation\n",
    "\n",
    "### Requirements\n",
    "\n",
    "- pytorch==1.7.1\n",
    "- easydict\n",
    "- yaml\n",
    "- imageio\n",
    "- sklearn\n",
    "- albumentations\n",
    "\n",
    "EfficientDet과 HRNet은 라이브러리를 설치해서 쓴게 아니라, 단일 `*.py`파일에 모든 코드를 합쳐서 import해서 썼습니다.  \n",
    "해당 코드를 있는 그대로 노트북에 옮기기에는 너무 길기 때문에 github에 업로드해두고, 소스코드 파일을 다운로드 해서 쓰겠습니다.\n",
    "\n",
    "EfficientDet의 pretrained weight는 https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch.git  \n",
    "HRNet의 pretrained weight는 https://github.com/leoxiaobin/deep-high-resolution-net.pytorch.git  \n",
    "를 참고했습니다.\n",
    "\n",
    "### Directory Structure\n",
    "\n",
    "```\n",
    "+ data\n",
    "  + ori\n",
    "    + train_imgs\n",
    "      - ...\n",
    "    + test_imgs\n",
    "      - ...\n",
    "    - sample_submission.csv\n",
    "    - train_df.csv\n",
    "    \n",
    "+ networks\n",
    "  + models\n",
    "    - efficientdet-d7.pth\n",
    "    - pose_hrnet_w48_384x288.pth\n",
    "  - __init__.py\n",
    "  - common.py\n",
    "  - efficientdet.py\n",
    "  - loader.py\n",
    "  - pose_hrnet.py\n",
    "  \n",
    "+ results # 학습 결과가 저장될 폴더\n",
    "  + effdet-train\n",
    "  + hrnet-train\n",
    "```\n",
    "\n",
    "### e.t.c.\n",
    "\n",
    "- `*.py`파일을 노트북에 합친 것이기 때문에 어색하거나 실행에 문제가 있는 점이 있을 수 있습니다.\n",
    "- 문제가 있을시에 원본 [github 소스코드](https://github.com/Kitsunetic/motion-keypoint-dacon.git)를 참고해주세요.\n",
    "- github 링크: https://github.com/Kitsunetic/motion-keypoint-dacon.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__download_files__ = {\n",
    "    # EfficientDet 모델 pretrained weights\n",
    "    \"networks/models/efficientdet-d7.pth\": \"https://github.com/Kitsunetic/motion-keypoint-dacon/releases/download/weights/efficientdet-d7.pth\",\n",
    "    \n",
    "    # HRNet 모델 pretrained weights\n",
    "    \"networks/models/pose_hrnet_w48_384x288.pth\": \"https://github.com/Kitsunetic/motion-keypoint-dacon/releases/download/weights/pose_hrnet_w48_384x288.pth\",\n",
    "    \n",
    "    # 소스코드 파일\n",
    "    \"networks/__init__.py\": \"\",\n",
    "    \"networks/common.py\": \"\",\n",
    "    \"networks/efficientdet.py\": \"\",\n",
    "    \"networks/loader.py\": \"\",\n",
    "    \"networks/pose_hrnet.py\": \"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path, url in __download_files__.items():\n",
    "    path = Path(path)\n",
    "    print(path)\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, 'wb') as f:\n",
    "        with requests.get(url) as response:\n",
    "            f.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions\n",
    "\n",
    "원래는 `./utils.py`에 있는 내용들입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Iterable, List\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from albumentations.core.transforms_interface import DualTransform\n",
    "from torch import Tensor\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed, deterministic=False):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = deterministic\n",
    "        torch.backends.cudnn.benchmark = not deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"\n",
    "    AverageMeter, referenced to https://dacon.io/competitions/official/235626/codeshare/1684\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.sum = 0\n",
    "        self.cnt = 0\n",
    "        self.avg = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        if n > 0:\n",
    "            self.sum += val * n\n",
    "            self.cnt += n\n",
    "            self.avg = self.sum / self.cnt\n",
    "\n",
    "    def get(self):\n",
    "        return self.avg\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAM(torch.optim.Optimizer):\n",
    "    def __init__(self, params, base_optimizer, rho=0.05, **kwargs):\n",
    "        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n",
    "\n",
    "        defaults = dict(rho=rho, **kwargs)\n",
    "        super(SAM, self).__init__(params, defaults)\n",
    "\n",
    "        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n",
    "        self.param_groups = self.base_optimizer.param_groups\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def first_step(self, zero_grad=False):\n",
    "        grad_norm = self._grad_norm()\n",
    "        for group in self.param_groups:\n",
    "            scale = group[\"rho\"] / (grad_norm + 1e-12)\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                e_w = p.grad * scale.to(p)\n",
    "                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n",
    "                self.state[p][\"e_w\"] = e_w\n",
    "\n",
    "        if zero_grad:\n",
    "            self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def second_step(self, zero_grad=False):\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                p.sub_(self.state[p][\"e_w\"])  # get back to \"w\" from \"w + e(w)\"\n",
    "\n",
    "        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n",
    "\n",
    "        if zero_grad:\n",
    "            self.zero_grad()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        assert closure is not None, \"Sharpness Aware Minimization requires closure, but it was not provided\"\n",
    "        closure = torch.enable_grad()(closure)  # the closure should do a full forward-backward pass\n",
    "\n",
    "        self.first_step(zero_grad=True)\n",
    "        closure()\n",
    "        self.second_step()\n",
    "\n",
    "    def _grad_norm(self):\n",
    "        shared_device = self.param_groups[0][\"params\"][\n",
    "            0\n",
    "        ].device  # put everything on the same device, in case of model parallelism\n",
    "        norm = torch.norm(\n",
    "            torch.stack(\n",
    "                [\n",
    "                    p.grad.norm(p=2).to(shared_device)\n",
    "                    for group in self.param_groups\n",
    "                    for p in group[\"params\"]\n",
    "                    if p.grad is not None\n",
    "                ]\n",
    "            ),\n",
    "            p=2,\n",
    "        )\n",
    "        return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLogger:\n",
    "    def __init__(self, filename, filemode=\"a\", use_color=True):\n",
    "        filename = Path(filename)\n",
    "        if filename.is_dir():\n",
    "            timestr = self._get_timestr().replace(\" \", \"_\").replace(\":\", \"-\")\n",
    "            filename = filename / f\"log_{timestr}.log\"\n",
    "        self.file = open(filename, filemode)\n",
    "        self.use_color = use_color\n",
    "\n",
    "    def _get_timestr(self):\n",
    "        n = datetime.now()\n",
    "        return f\"{n.year:04d}-{n.month:02d}-{n.day:02d} {n.hour:02d}:{n.minute:02d}:{n.second:02d}\"\n",
    "\n",
    "    def _write(self, msg, level):\n",
    "        timestr = self._get_timestr()\n",
    "        out = f\"[{timestr} {level}] {msg}\"\n",
    "\n",
    "        if self.use_color:\n",
    "            if level == \" INFO\":\n",
    "                print(\"\\033[34m\" + out + \"\\033[0m\")\n",
    "            elif level == \" WARN\":\n",
    "                print(\"\\033[35m\" + out + \"\\033[0m\")\n",
    "            elif level == \"ERROR\":\n",
    "                print(\"\\033[31m\" + out + \"\\033[0m\")\n",
    "            elif level == \"FATAL\":\n",
    "                print(\"\\033[43m\\033[1m\" + out + \"\\033[0m\")\n",
    "            else:\n",
    "                print(out)\n",
    "        else:\n",
    "            print(out)\n",
    "        self.file.write(out + \"\\r\\n\")\n",
    "\n",
    "    def debug(self, *msg):\n",
    "        msg = \" \".join(map(str, msg))\n",
    "        self._write(msg, \"DEBUG\")\n",
    "\n",
    "    def info(self, *msg):\n",
    "        msg = \" \".join(map(str, msg))\n",
    "        self._write(msg, \" INFO\")\n",
    "\n",
    "    def warn(self, *msg):\n",
    "        msg = \" \".join(map(str, msg))\n",
    "        self._write(msg, \" WARN\")\n",
    "\n",
    "    def error(self, *msg):\n",
    "        msg = \" \".join(map(str, msg))\n",
    "        self._write(msg, \"ERROR\")\n",
    "\n",
    "    def fatal(self, *msg):\n",
    "        msg = \" \".join(map(str, msg))\n",
    "        self._write(msg, \"FATAL\")\n",
    "\n",
    "    def flush(self):\n",
    "        self.file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints(image: np.ndarray, keypoints: np.ndarray):\n",
    "    edges = [\n",
    "        (0, 1),\n",
    "        (0, 2),\n",
    "        (2, 4),\n",
    "        (1, 3),\n",
    "        (6, 8),\n",
    "        (8, 10),\n",
    "        (5, 7),\n",
    "        (7, 9),\n",
    "        (11, 13),\n",
    "        (13, 15),\n",
    "        (12, 14),\n",
    "        (14, 16),\n",
    "        (5, 6),\n",
    "        (15, 22),\n",
    "        (16, 23),\n",
    "        (11, 21),\n",
    "        (21, 12),\n",
    "        (20, 21),\n",
    "        (5, 20),\n",
    "        (6, 20),\n",
    "        (17, 6),\n",
    "        (17, 5),\n",
    "    ]\n",
    "    keypoint_names = [\n",
    "        \"nose_x\",\n",
    "        \"nose_y\",\n",
    "        \"left_eye_x\",\n",
    "        \"left_eye_y\",\n",
    "        \"right_eye_x\",\n",
    "        \"right_eye_y\",\n",
    "        \"left_ear_x\",\n",
    "        \"left_ear_y\",\n",
    "        \"right_ear_x\",\n",
    "        \"right_ear_y\",\n",
    "        \"left_shoulder_x\",\n",
    "        \"left_shoulder_y\",\n",
    "        \"right_shoulder_x\",\n",
    "        \"right_shoulder_y\",\n",
    "        \"left_elbow_x\",\n",
    "        \"left_elbow_y\",\n",
    "        \"right_elbow_x\",\n",
    "        \"right_elbow_y\",\n",
    "        \"left_wrist_x\",\n",
    "        \"left_wrist_y\",\n",
    "        \"right_wrist_x\",\n",
    "        \"right_wrist_y\",\n",
    "        \"left_hip_x\",\n",
    "        \"left_hip_y\",\n",
    "        \"right_hip_x\",\n",
    "        \"right_hip_y\",\n",
    "        \"left_knee_x\",\n",
    "        \"left_knee_y\",\n",
    "        \"right_knee_x\",\n",
    "        \"right_knee_y\",\n",
    "        \"left_ankle_x\",\n",
    "        \"left_ankle_y\",\n",
    "        \"right_ankle_x\",\n",
    "        \"right_ankle_y\",\n",
    "        \"neck_x\",\n",
    "        \"neck_y\",\n",
    "        \"left_palm_x\",\n",
    "        \"left_palm_y\",\n",
    "        \"right_palm_x\",\n",
    "        \"right_palm_y\",\n",
    "        \"spine2(back)_x\",\n",
    "        \"spine2(back)_y\",\n",
    "        \"spine1(waist)_x\",\n",
    "        \"spine1(waist)_y\",\n",
    "        \"left_instep_x\",\n",
    "        \"left_instep_y\",\n",
    "        \"right_instep_x\",\n",
    "        \"right_instep_y\",\n",
    "    ]\n",
    "    image = image.copy()\n",
    "\n",
    "    np.random.seed(42)\n",
    "    colors = {k: tuple(map(int, np.random.randint(0, 255, 3))) for k in range(24)}\n",
    "    x1, y1 = max(0, min(keypoints[:, 0]) - 10), max(0, min(keypoints[:, 1]) - 10)\n",
    "    x2, y2 = min(image.shape[1], max(keypoints[:, 0]) + 10), min(image.shape[0], max(keypoints[:, 1]) + 10)\n",
    "    # cv2.rectangle(image, (x1, y1), (x2, y2), (255, 100, 91), 3)\n",
    "\n",
    "    for i, keypoint in enumerate(keypoints):\n",
    "        cv2.circle(image, tuple(keypoint), 3, colors.get(i), thickness=3, lineType=cv2.FILLED)\n",
    "\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            f\"{i}: {keypoint_names[i*2]}\",\n",
    "            tuple(keypoint),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            (0, 0, 0),\n",
    "            1,\n",
    "        )\n",
    "\n",
    "    for i, edge in enumerate(edges):\n",
    "        cv2.line(\n",
    "            image,\n",
    "            tuple(keypoints[edge[0]]),\n",
    "            tuple(keypoints[edge[1]]),\n",
    "            colors.get(edge[0]),\n",
    "            3,\n",
    "            lineType=cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_keypoints_show(image: np.ndarray, keypoints: np.ndarray):\n",
    "    image = draw_keypoints(image, keypoints)\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(\"example.png\")\n",
    "    # imageio.imwrite(\"example.png\", image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def heatmaps2keypoints(p: torch.Tensor):\n",
    "    if p.dim() == 3:\n",
    "        W = p.size(2)\n",
    "        pos = torch.argmax(p.flatten(1), 1)\n",
    "        y = pos // W\n",
    "        x = pos % W\n",
    "        keypoint = torch.stack([x, y], 1).type(torch.float)\n",
    "    elif p.dim() == 4:\n",
    "        W = p.size(3)\n",
    "        pos = torch.argmax(p.flatten(2), 2)\n",
    "        y = pos // W\n",
    "        x = pos % W\n",
    "        keypoint = torch.stack([x, y], 2).type(torch.float)\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Expected input tensor dimention 3 or 4, but {p.shape}\")\n",
    "\n",
    "    return keypoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def keypoints2heatmaps(\n",
    "    k: torch.Tensor,\n",
    "    h=768 // 4,\n",
    "    w=576 // 4,\n",
    "    smooth=False,\n",
    "    smooth_size=3,\n",
    "    smooth_values=[0.1, 0.4, 0.8],\n",
    "):\n",
    "    k = k.type(torch.int64)\n",
    "    c = torch.zeros(k.size(0), h, w, dtype=torch.float32)\n",
    "    for i, (x, y) in enumerate(k):\n",
    "        if smooth:\n",
    "            for d, s in zip(range(smooth_size, 0, -1), smooth_values):\n",
    "                c[i, max(y - d, 0) : min(y + d, h), max(x - d, 0) : min(x + d, w)] = s\n",
    "        c[i, y, x] = 1.0\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keypoint2box(keypoint, padding=0):\n",
    "    return np.array(\n",
    "        [\n",
    "            keypoint[:, 0].min() - padding,\n",
    "            keypoint[:, 1].min() - padding,\n",
    "            keypoint[:, 0].max() + padding,\n",
    "            keypoint[:, 1].max() + padding,\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(\n",
    "    x: torch.Tensor,\n",
    "    mean=torch.tensor([0.485, 0.456, 0.406], dtype=torch.float32),\n",
    "    std=torch.tensor([0.229, 0.224, 0.225], dtype=torch.float32),\n",
    "):\n",
    "    if x.dim() == 4:\n",
    "        mean = mean.view(1, 3, 1, 1).to(x.device)\n",
    "        std = std.view(1, 3, 1, 1).to(x.device)\n",
    "    elif x.dim() == 3:\n",
    "        mean = mean.view(3, 1, 1).to(x.device)\n",
    "        std = std.view(3, 1, 1).to(x.device)\n",
    "\n",
    "    return x * std + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tensor2Image:\n",
    "    def __init__(\n",
    "        self,\n",
    "        mean: torch.Tensor = torch.tensor([0.485, 0.456, 0.406], dtype=torch.float),\n",
    "        std: torch.Tensor = torch.tensor([0.229, 0.224, 0.225], dtype=torch.float),\n",
    "    ):\n",
    "        if not isinstance(mean, torch.Tensor):\n",
    "            mean = torch.tensor(mean, dtype=torch.float)\n",
    "        if not isinstance(std, torch.Tensor):\n",
    "            std = torch.tensor(std, dtype=torch.float)\n",
    "\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, x: torch.Tensor):\n",
    "        assert x.dim() in (3, 4)\n",
    "        if x.dim() == 3:\n",
    "            assert x.size(0) in (1, 3, 4)\n",
    "            x = 255 * (x.permute(1, 2, 0) * self.std.view(1, 1, 3) + self.mean.view(1, 1, 3))\n",
    "        if x.dim() == 4:\n",
    "            assert x.size(1) in (1, 3, 4)\n",
    "            x = 255 * (x.permute(0, 2, 3, 1) * self.std.view(1, 1, 1, 3) + self.mean.view(1, 1, 1, 3))\n",
    "        return x.type(torch.uint8).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshows(*ims, figsize=None):\n",
    "    figsize = figsize or (len(ims) * 6, 4)\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i, im in enumerate(ims):\n",
    "        plt.subplot(1, len(ims), i + 1)\n",
    "        plt.imshow(im)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Efficientdet-d7 학습\n",
    "\n",
    "원래는 `./config/effdet-d7.yaml`, `./main-effdet-train.py`에 있는 내용입니다.\n",
    "\n",
    "KFold는 하지 않고, 1fold 만 학습합니다.\n",
    "\n",
    "두 개의 파일을 생성합니다.\n",
    "\n",
    "- `./results/effdet-train/`\n",
    "- `./results/effdet-train/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__effdet_config_str__ = \"\"\"\n",
    "seed: 20210309\n",
    "result_dir: results/effdet-train\n",
    "comment: null\n",
    "\n",
    "det_model: \n",
    "  name: efficientdet-d7\n",
    "  # pretrained: null\n",
    "  # pretrained: results/effdet-train/ckpt-efficientdet-d7_1.pth\n",
    "  pretrained: results/effdet-train/ckpt-efficientdet-d7_SAM_1.pth\n",
    "\n",
    "dataset:\n",
    "  dir: data/ori\n",
    "  batch_size: 1\n",
    "  num_cpus: 1\n",
    "  padding: 20\n",
    "  \n",
    "  crop:\n",
    "    - 192\n",
    "    - 28\n",
    "    - 1728\n",
    "    - 1052\n",
    "\n",
    "  input_width: 1536 #768 #1536\n",
    "  input_height: 1024 #512 #1024\n",
    "  \n",
    "train:\n",
    "  SAM: false\n",
    "  earlystop_patience: 10\n",
    "  start_epoch: 1\n",
    "  final_epoch: 200\n",
    "  \n",
    "  folds:\n",
    "    - 1\n",
    "    # - 2\n",
    "    # - 3\n",
    "    # - 4\n",
    "    # - 5\n",
    "  checkpoints:\n",
    "    - null\n",
    "    # - null\n",
    "    # - null\n",
    "    # - null\n",
    "    # - null\n",
    "\n",
    "  # lr: 0.000001\n",
    "  lr: 0.0001\n",
    "  scheduler:\n",
    "    # type: CosineAnnealingWarmUpRestarts\n",
    "    # params:\n",
    "    #   T_0: 10\n",
    "    #   T_mult: 1\n",
    "    #   eta_max: 0.001\n",
    "    #   T_up: 5\n",
    "    #   gamma: 0.5\n",
    "    # type: CosineAnnealingWarmRestarts\n",
    "    # params:\n",
    "    #   T_0: 10\n",
    "    #   T_mult: 1\n",
    "    #   eta_min: 0.00001\n",
    "    #   verbose: false\n",
    "    type: ReduceLROnPlateau\n",
    "    params:\n",
    "      factor: 0.5\n",
    "      patience: 3\n",
    "      verbose: true\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "from multiprocessing import cpu_count\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import imageio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import yaml\n",
    "from easydict import EasyDict\n",
    "from PIL import Image\n",
    "from torch import nn, optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import networks\n",
    "import options\n",
    "import utils\n",
    "from datasets import get_det_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetTrainOutput:\n",
    "    def __init__(self):\n",
    "        self.loss = utils.AverageMeter()\n",
    "\n",
    "    def freeze(self):\n",
    "        self.loss = self.loss()\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetTrainer:\n",
    "    _tqdm_ = dict(ncols=100, leave=False, file=sys.stdout)\n",
    "\n",
    "    def __init__(self, C, fold=1, checkpoint=None):\n",
    "        self.C = C\n",
    "        self.fold = fold\n",
    "\n",
    "        self.det_model = networks.EfficientDetFinetune(\n",
    "            self.C.det_model.name, pretrained=True, finetune=self.C.det_model.finetune.do\n",
    "        )\n",
    "        self.det_model.cuda()\n",
    "\n",
    "        # Optimizer\n",
    "        if self.C.train.SAM:\n",
    "            self.optimizer = utils.SAM(self.det_model.parameters(), optim.AdamW, lr=self.C.lr)\n",
    "        else:\n",
    "            self.optimizer = optim.AdamW(self.det_model.parameters(), lr=self.C.lr)\n",
    "\n",
    "        self.epoch = self.C.start_epoch\n",
    "        self.best_loss = math.inf\n",
    "        self.earlystop_cnt = 0\n",
    "\n",
    "        # Dataset\n",
    "        self.dl_train, self.dl_valid = get_det_dataset(C, self.fold)\n",
    "\n",
    "        # Load Checkpoint\n",
    "        if self.C.det_model.pretrained is not None:\n",
    "            self.load(self.C.det_model.pretrained)\n",
    "\n",
    "        if checkpoint is not None:\n",
    "            self.load(checkpoint)\n",
    "\n",
    "        # Scheduler\n",
    "        self.scheduler = options.get_scheduler(self.C, self.optimizer, self.epoch - 2)\n",
    "\n",
    "    def save(self, path):\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model\": self.det_model.state_dict(),\n",
    "                \"optimizer\": self.optimizer.state_dict(),\n",
    "                \"epoch\": self.epoch,\n",
    "                \"best_loss\": self.best_loss,\n",
    "                \"earlystop_cnt\": self.earlystop_cnt,\n",
    "            },\n",
    "            path,\n",
    "        )\n",
    "\n",
    "    def load(self, path):\n",
    "        print(\"Load pretrained\", path)\n",
    "        ckpt = torch.load(path)\n",
    "        self.det_model.load_state_dict(ckpt[\"model\"])\n",
    "        self.optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
    "        self.epoch = ckpt[\"epoch\"] + 1\n",
    "        self.best_loss = ckpt[\"best_loss\"]\n",
    "        self.earlystop_cnt = ckpt[\"earlystop_cnt\"]\n",
    "\n",
    "    def close(self):\n",
    "        self.logger.close()\n",
    "\n",
    "    def train_loop(self):\n",
    "        self.det_model.train()\n",
    "\n",
    "        O = DetTrainOutput()\n",
    "        with tqdm(total=len(self.dl_train.dataset), **self._tqdm_, desc=f\"Train {self.epoch:03d}\") as t:\n",
    "            for files, imgs, annots in self.dl_train:\n",
    "                imgs_, annots_ = imgs.cuda(non_blocking=True), annots.cuda(non_blocking=True)\n",
    "                loss = self.det_model(imgs_, annots_)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                if isinstance(self.optimizer, utils.SAM):\n",
    "                    self.optimizer.first_step()\n",
    "                    self.det_model(imgs_, annots_).backward()\n",
    "                    self.optimizer.second_step()\n",
    "                else:\n",
    "                    self.optimizer.step()\n",
    "\n",
    "                O.loss.update(loss.item(), len(files))\n",
    "                t.set_postfix_str(f\"loss: {loss.item():.6f}\", refresh=False)\n",
    "                t.update(len(files))\n",
    "\n",
    "        return O.freeze()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def valid_loop(self):\n",
    "        self.det_model.eval()\n",
    "\n",
    "        O = DetTrainOutput()\n",
    "        with tqdm(total=len(self.dl_valid.dataset), **self._tqdm_, desc=f\"Valid {self.epoch:03d}\") as t:\n",
    "            for files, imgs, annots in self.dl_valid:\n",
    "                imgs_, annots_ = imgs.cuda(non_blocking=True), annots.cuda(non_blocking=True)\n",
    "                loss = self.det_model(imgs_, annots_)\n",
    "\n",
    "                O.loss.update(loss.item(), len(files))\n",
    "                t.set_postfix_str(f\"loss: {loss.item():.6f}\", refresh=False)\n",
    "                t.update(len(files))\n",
    "\n",
    "        return O.freeze()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def callback(self, to: DetTrainOutput, vo: DetTrainOutput):\n",
    "        self.C.log.info(\n",
    "            f\"Epoch: {self.epoch:03d},\",\n",
    "            f\"loss: {to.loss:.6f};{vo.loss:.6f},\",\n",
    "        )\n",
    "        self.C.log.flush()\n",
    "\n",
    "        if isinstance(self.scheduler, lr_scheduler.CosineAnnealingWarmRestarts):\n",
    "            self.scheduler.step()\n",
    "        elif isinstance(self.scheduler, lr_scheduler.ReduceLROnPlateau):\n",
    "            self.scheduler.step(vo.loss)\n",
    "\n",
    "        if self.best_loss > vo.loss:\n",
    "            self.best_loss = vo.loss\n",
    "            self.earlystop_cnt = 0\n",
    "            self.save(Path(self.C.result_dir) / f\"ckpt-{self.C.uid}_{self.fold}.pth\")\n",
    "        else:\n",
    "            self.earlystop_cnt += 1\n",
    "\n",
    "    def fit(self):\n",
    "        for self.epoch in range(self.epoch, self.C.final_epoch + 1):\n",
    "            if self.C.finetune.do:\n",
    "                if self.epoch <= self.C.finetune.step1_epochs:\n",
    "                    self.det_model.unfreeze_tail()\n",
    "                elif self.epoch <= self.C.finetune.step2_epochs:\n",
    "                    self.det_model.unfreeze_head()\n",
    "                else:\n",
    "                    self.det_model.unfreeze()\n",
    "\n",
    "            to = self.train_loop()\n",
    "            vo = self.valid_loop()\n",
    "            self.callback(to, vo)\n",
    "\n",
    "            if self.earlystop_cnt > self.C.earlystop_patience:\n",
    "                self.C.log.info(f\"Stop training at epoch\", self.epoch)\n",
    "                break\n",
    "\n",
    "        self.load(Path(self.C.result_dir) / f\"ckpt-{self.C.uid}_{self.fold}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_det_train():\n",
    "    C = EasyDict(yaml.load(__effdet_config_str__, yaml.FullLoader))\n",
    "\n",
    "    for fold, checkpoint in zip(C.train.folds, C.train.checkpoints):\n",
    "        with open(args.config_file, \"r\") as f:\n",
    "            C = EasyDict(yaml.load(f, yaml.FullLoader))\n",
    "            Path(C.result_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        if C.dataset.num_cpus < 0:\n",
    "            C.dataset.num_cpus = cpu_count()\n",
    "        C.uid = f\"{C.det_model.name}\"\n",
    "        C.uid += f\"-sam\" if C.train.SAM else \"\"\n",
    "        C.uid += f\"-{C.dataset.input_width}x{C.dataset.input_height}\"\n",
    "        C.uid += f\"-pad{C.dataset.padding}\"\n",
    "        C.uid += f\"-{C.comment}\" if C.comment is not None else \"\"\n",
    "        C.uid += f\"_{C.train.fold}\"\n",
    "\n",
    "        trainer = DetTrainer(C, fold, checkpoint)\n",
    "        trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_det_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Efficientdet-d7으로 test_imgs에서 roi만 잘라내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
